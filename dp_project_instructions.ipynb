{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions for Running the Code\n",
        "\n",
        "To reproduce the results and execute the code of this repo successfully, please follow these steps:\n",
        "\n",
        "1. Ensure that you are connected to a T4 GPU runtime, as our code relies on NVIDIA CUDA for acceleration and may not work efficiently on CPUs.\n",
        "2. Run the code snippets provided below sequentially.\n",
        "3. Pay attention to any comments within the code snippets.\n",
        "4. After running all code snippets, you can see the evaluation metrics and reconstructed images in experiments folder.\n",
        "\n",
        "Please note: You need to have access to view the [dataset](https://drive.google.com/drive/folders/1mElxNk6-XAfSeJcK76oZuXvU5zAYF7FS?usp=sharing), and since we're running this on Drive, you need to have enough storage space in your Google Drive for this to work."
      ],
      "metadata": {
        "id": "HgQ2ONCCIxci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BRkQjjsO1Ind",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b52ba3-3282-4367-bde9-9f82799df9af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting the Google Drive onto Colab.\n",
        "# Note: Connect to the T4 GPU runtime as our code requires GPU acceleration due to NVIDIA CUDA dependencies.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the following code only when executing it for the first time to clone the GitHub repository into your google drive.\n",
        "\n",
        "# UNCOMMENT THE CODE BELOW WHEN RUNNING FOR THE FIRST TIME.\n",
        "%%bash\n",
        "cd /content/drive/MyDrive/\n",
        "mkdir -p manogna-dp-project\n",
        "cd manogna-dp-project\n",
        "git clone https://github.com/manognachennuru/rog.git\n"
      ],
      "metadata": {
        "id": "du8rh6Zy1cQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f035c616-0922-4311-9bc7-0a7da21d46e4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'rog'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below coding snippet is to change the current working directory to the home directory"
      ],
      "metadata": {
        "id": "htw_w99dTWIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the current working directory at the beginning\n",
        "print(\"Working Directory at the beginning:\", end=\"\")\n",
        "!pwd\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the path to the directory where your data is located\n",
        "home_directory = \"/content/drive/MyDrive/manogna-dp-project/rog\"\n",
        "\n",
        "# Change the current directory to the data directory\n",
        "os.chdir(home_directory)\n",
        "\n",
        "# Printing the current working directory after changing\n",
        "print(\"Working Directory:\", end=\"\")\n",
        "!pwd\n"
      ],
      "metadata": {
        "id": "z1nVchi52Sg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e12d98-b697-45fd-9f40-920ea82284d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working Directory at the beginning:/content\n",
            "Working Directory:/content/drive/MyDrive/manogna-dp-project/rog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Python Packages\n",
        "\n",
        "In the following cells, we'll install the required Python packages. Some packages are installed using a `requirements.txt` file, while others will be installed individually. If you encounter any errors during installation, you can safely ignore them unless they prevent the notebook from running successfully.\n",
        "\n",
        "Please proceed to the next cells for package installation.\n"
      ],
      "metadata": {
        "id": "5VNEQ3g4sdYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Python packages\n",
        "# Some packages are installed using requirements.txt. Individual statements are provided for those that are not installed using requirements.\n",
        "# Ignore the error for opencv_python==4.5.2.52 as it seems there's no matching distribution.\n",
        "\n",
        "!pip3 install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "BNobgpcK2dBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2f721c-ffa7-4723-ef23-486a288ca037"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting inplace_abn==1.1.0 (from -r requirements.txt (line 1))\n",
            "  Downloading inplace-abn-1.1.0.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lpips==0.1.4 (from -r requirements.txt (line 2))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.19.5 (from -r requirements.txt (line 3))\n",
            "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv_python==4.5.2.52 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv_python==4.5.2.52\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install inplace-abn"
      ],
      "metadata": {
        "id": "OW74CoqIZdas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9809c19c-c6a4-4e78-95ca-083c922efdf7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting inplace-abn\n",
            "  Using cached inplace-abn-1.1.0.tar.gz (137 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: inplace-abn\n",
            "  Building wheel for inplace-abn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inplace-abn: filename=inplace_abn-1.1.0-cp310-cp310-linux_x86_64.whl size=4199522 sha256=727a28693e0bdeff59a21f8d0943bdf4c4119e5481122521713e753737ff9e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f2/05/97ab74dbf2ed6d592684f76d0ae8f33f66bbafa0ec5b53b416\n",
            "Successfully built inplace-abn\n",
            "Installing collected packages: inplace-abn\n",
            "Successfully installed inplace-abn-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lpips"
      ],
      "metadata": {
        "id": "pNpXorYBaf3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237bee5a-03c6-42be-93d1-10d82d905ae1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Using cached lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lpips\n",
            "Successfully installed lpips-0.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check installations\n",
        "\n",
        " The below code is just to see if all the dependencies are installed properly. I put them in try-except blocks so that it won't raise an error. It instead prints a statement if the respective package is not installed."
      ],
      "metadata": {
        "id": "WLPA_PL3s2Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import inplace_abn\n",
        "    print(\"inplace_abn version:\", inplace_abn.__version__)\n",
        "except ImportError:\n",
        "    print(\"inplace_abn is not installed\")\n",
        "\n",
        "try:\n",
        "    import lpips\n",
        "    print(\"lpips installed\")\n",
        "except ImportError:\n",
        "    print(\"lpips is not installed\")\n",
        "\n",
        "try:\n",
        "    import numpy\n",
        "    print(\"numpy version:\", numpy.__version__)\n",
        "except ImportError:\n",
        "    print(\"numpy is not installed\")\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "    print(\"opencv-python version:\", cv2.__version__)  # OpenCV is often imported as cv2\n",
        "except ImportError:\n",
        "    print(\"opencv-python is not installed\")\n",
        "\n",
        "try:\n",
        "    import pandas\n",
        "    print(\"pandas version:\", pandas.__version__)\n",
        "except ImportError:\n",
        "    print(\"pandas is not installed\")\n",
        "\n",
        "try:\n",
        "    import PIL\n",
        "    print(\"Pillow version:\", PIL.__version__)\n",
        "except ImportError:\n",
        "    print(\"Pillow is not installed\")\n",
        "\n",
        "try:\n",
        "    import yaml\n",
        "    print(\"PyYAML version:\", yaml.__version__)\n",
        "except ImportError:\n",
        "    print(\"PyYAML is not installed\")\n",
        "\n",
        "try:\n",
        "    import scipy\n",
        "    print(\"scipy version:\", scipy.__version__)\n",
        "except ImportError:\n",
        "    print(\"scipy is not installed\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "except ImportError:\n",
        "    print(\"PyTorch is not installed\")\n",
        "\n",
        "try:\n",
        "    import torchvision\n",
        "    print(\"torchvision version:\", torchvision.__version__)\n",
        "except ImportError:\n",
        "    print(\"torchvision is not installed\")\n"
      ],
      "metadata": {
        "id": "QUqYWzmGMqIl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15ca7deb-1bc0-4449-c8d6-2d4d92e25fcf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inplace_abn version: 1.1.0\n",
            "lpips installed\n",
            "numpy version: 1.25.2\n",
            "opencv-python version: 4.8.0\n",
            "pandas version: 2.0.3\n",
            "Pillow version: 9.4.0\n",
            "PyYAML version: 6.0.1\n",
            "scipy version: 1.11.4\n",
            "PyTorch version: 2.2.1+cu121\n",
            "torchvision version: 0.17.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Download Pretrained Models\n",
        "\n",
        "In this step, we'll download the pretrained models and place them under the `model_zoos` directory. Bash commands will be used to move the files into the appropriate folder.\n",
        "\n",
        "Please execute the following commands to download and organize the pretrained models.\n",
        "\n",
        "[link to the pre-trained models](https://huggingface.co/erickyue/rog_modelzoo/tree/main)\n"
      ],
      "metadata": {
        "id": "-bp0JLx1tJTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Uncomment the following lines if you're running it for the first time.\n",
        "\n",
        "#Change directory to the model_zoos folder\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/manogna-dp-project/rog/model_zoos\")\n",
        "\n",
        "#Print the current directory\n",
        "!pwd\n",
        "\n",
        "#Install git-lfs for handling large files\n",
        "!apt install git-lfs\n",
        "!git lfs install\n",
        "\n",
        "#Clone the repository containing pretrained models\n",
        "!git clone https://huggingface.co/erickyue/rog_modelzoo\n",
        "\n",
        "#Move the downloaded files to the current directory\n",
        "!mv -v /content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/*  ./\n",
        "\n",
        "#Remove the empty rog_modelzoo directory\n",
        "!rm -rf rog_modelzoo/"
      ],
      "metadata": {
        "id": "H2K8wZyAElpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef40a87-38e6-427b-e758-f0f05be688fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/manogna-dp-project/rog/model_zoos\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'rog_modelzoo'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 11 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (11/11), 8.51 KiB | 65.00 KiB/s, done.\n",
            "Filtering content: 100% (4/4), 747.60 MiB | 56.16 MiB/s, done.\n",
            "fatal: cannot exec '/content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/.git/hooks/post-checkout': Permission denied\n",
            "renamed '/content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/denoiser.pth' -> './denoiser.pth'\n",
            "renamed '/content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/kernels_bicubicx234.mat' -> './kernels_bicubicx234.mat'\n",
            "renamed '/content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/postmodel.pth' -> './postmodel.pth'\n",
            "renamed '/content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/README.md' -> './README.md'\n",
            "renamed '/content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/tresnet.pth' -> './tresnet.pth'\n",
            "renamed '/content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/usrgan.pth' -> './usrgan.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Access\n",
        "\n",
        "In order to reproduce the results, you need to access the shared dataset. I have shared the folder with Dr. Fan (Course Instructor) and Harshitha (Teaching Assistant). If you're using with different account, Please send me a request.\n",
        "\n",
        "1. Locate the shared folder link provided to you.\n",
        "2. Go to your Google Drive and click on \"Shared with me\" to find the folder.\n",
        "3. Right-click on the shared folder and select \"Add shortcut to Drive.\"\n",
        "4. Save the shortcut in the following directory: `/content/drive/MyDrive`.\n",
        "\n",
        "Once you have added the shortcut, you will be able to access the dataset from within the notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "AUpwp5LbAYHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LINK TO SHARED GOOGLE DRIVE:\n",
        "https://drive.google.com/drive/folders/1mElxNk6-XAfSeJcK76oZuXvU5zAYF7FS?usp=drive_link"
      ],
      "metadata": {
        "id": "LVuHCnmAAVZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTE: Here, you add shortcut to the shared folder and save it in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "eTEziKnpouQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code snippet changes the active directory. It is needed to avoid path conflicts later on."
      ],
      "metadata": {
        "id": "VmuTapAeufph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory where your data is located\n",
        "data_directory = \"/content/drive/MyDrive/manogna-dp-project/rog\"\n",
        "\n",
        "# Change the current directory to the data directory\n",
        "os.chdir(data_directory)\n",
        "\n",
        "# Print the current working directory after changing\n",
        "!pwd"
      ],
      "metadata": {
        "id": "4Ar45suOJWmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e8d6b1-d743-42bb-a7eb-e71c26ba0014"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/manogna-dp-project/rog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print Updated Datapair File\n",
        "\n",
        "I have updated the `datapair.dat` file to match the paths of the current dataset. Please note that the paths in the `datapair.dat` file have been modified to correspond to the paths in the current dataset, ensuring compatibility with the code execution.\n"
      ],
      "metadata": {
        "id": "Tma0a8LGuWSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code snippet to print some of the contents of datapair.dat\n",
        "\n",
        "# Define the path to the datapair file\n",
        "datapair_file_path = \"data/datapair.dat\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Load the datapair from the file\n",
        "with open(datapair_file_path, \"rb\") as fp:\n",
        "    record = pickle.load(fp)\n",
        "\n",
        "# Print the datapair\n",
        "print(\"datapair:\")\n",
        "for index, item in enumerate(record[\"data_pair\"]):\n",
        "    print(f\"Index {index}: {item}\")\n",
        "    if index == 10:\n",
        "      break\n",
        "\n",
        "# Check if 'root' key exists and print it if it does\n",
        "if \"root\" in record:\n",
        "    print(f\"Root directory: {record['root']}\")\n"
      ],
      "metadata": {
        "id": "nrMibKyqPMBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b1365b2-e283-4549-a891-ba641f7d4d95"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datapair:\n",
            "Index 0: ('NORMAL', 'IM-0533-0001-0001.jpeg', 0)\n",
            "Index 1: ('NORMAL', 'IM-0533-0001-0002.jpeg', 0)\n",
            "Index 2: ('NORMAL', 'IM-0526-0001.jpeg', 0)\n",
            "Index 3: ('NORMAL', 'IM-0534-0001.jpeg', 0)\n",
            "Index 4: ('NORMAL', 'IM-0522-0001.jpeg', 0)\n",
            "Index 5: ('NORMAL', 'IM-0532-0001.jpeg', 0)\n",
            "Index 6: ('NORMAL', 'IM-0537-0001.jpeg', 0)\n",
            "Index 7: ('NORMAL', 'IM-0533-0001.jpeg', 0)\n",
            "Index 8: ('NORMAL', 'IM-0524-0001.jpeg', 0)\n",
            "Index 9: ('NORMAL', 'IM-0535-0001.jpeg', 0)\n",
            "Index 10: ('NORMAL', 'IM-0523-0001-0003.jpeg', 0)\n",
            "Root directory: /content/drive/MyDrive/chest_xray_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Model and Evaluating the Performance\n",
        "\n",
        "The following snippets run some of the examples. The results will be stored under the `experiments` directory.\n",
        "\n",
        "Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) of the results are evaluated and printed.\n",
        "\n",
        "Original and reconstructed images (for minimum runnable image set) are also displayed in the experiments folder to visualize the results.\n"
      ],
      "metadata": {
        "id": "DHxhhWSququf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py"
      ],
      "metadata": {
        "id": "xkZBLfizFrS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bf9da1a-70df-4078-dd8d-2efbcec1e169"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "T_max               : 100\n",
            "batch_size          : 4\n",
            "channels            : 3\n",
            "compress            : none\n",
            "denoiser            : model_zoos/denoiser.pth\n",
            "device              : cuda\n",
            "dpsnr               : -20\n",
            "fed_lr              : 0.0001\n",
            "fedalg              : fedavg\n",
            "gpu                 : [0]\n",
            "half                : False\n",
            "joint_postmodel     : model_zoos/postmodel.pth\n",
            "kernel              : model_zoos/kernels_bicubicx234.mat\n",
            "model               : resnet18\n",
            "noise_level         : 0.01\n",
            "num_classes         : 2\n",
            "output_folder       : experiments\n",
            "printevery          : 1\n",
            "refine              : False\n",
            "rog_lr              : 0.05\n",
            "sample_size         : [128, 128]\n",
            "sf                  : 4\n",
            "tau                 : 10\n",
            "test_data_dir       : data\n",
            "thres               : 2\n",
            "train_data_dir      : data\n",
            "tresnet             : model_zoos/tresnet.pth\n",
            "usrnet              : model_zoos/usrgan.pth\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/content/drive/MyDrive/manogna-dp-project/rog/networks/metanet.py:81: UserWarning: Patching for module <class 'networks.resnet.BasicBlock'> is not implemented.\n",
            "  warnings.warn(f'Patching for module {module.__class__} is not implemented.')\n",
            "iter: 0 loss: 1.7579e+01\n",
            "iter: 1 loss: 1.2523e+01\n",
            "iter: 2 loss: 1.1077e+01\n",
            "iter: 3 loss: 1.0335e+01\n",
            "iter: 4 loss: 9.8275e+00\n",
            "iter: 5 loss: 9.0553e+00\n",
            "iter: 6 loss: 8.3199e+00\n",
            "iter: 7 loss: 7.9231e+00\n",
            "iter: 8 loss: 7.3993e+00\n",
            "iter: 9 loss: 6.9742e+00\n",
            "iter: 10 loss: 6.5325e+00\n",
            "iter: 11 loss: 6.2064e+00\n",
            "iter: 12 loss: 5.8080e+00\n",
            "iter: 13 loss: 5.6384e+00\n",
            "iter: 14 loss: 5.3832e+00\n",
            "iter: 15 loss: 5.2984e+00\n",
            "iter: 16 loss: 5.0464e+00\n",
            "iter: 17 loss: 4.8567e+00\n",
            "iter: 18 loss: 4.6139e+00\n",
            "iter: 19 loss: 4.5115e+00\n",
            "iter: 20 loss: 4.3116e+00\n",
            "iter: 21 loss: 4.1960e+00\n",
            "iter: 22 loss: 4.1048e+00\n",
            "iter: 23 loss: 3.9459e+00\n",
            "iter: 24 loss: 3.8233e+00\n",
            "iter: 25 loss: 3.7473e+00\n",
            "iter: 26 loss: 3.7037e+00\n",
            "iter: 27 loss: 3.6374e+00\n",
            "iter: 28 loss: 3.6152e+00\n",
            "iter: 29 loss: 3.5703e+00\n",
            "iter: 30 loss: 3.5205e+00\n",
            "iter: 31 loss: 3.4056e+00\n",
            "iter: 32 loss: 3.3535e+00\n",
            "iter: 33 loss: 3.2183e+00\n",
            "iter: 34 loss: 3.2207e+00\n",
            "iter: 35 loss: 3.1560e+00\n",
            "iter: 36 loss: 3.1429e+00\n",
            "iter: 37 loss: 3.0810e+00\n",
            "iter: 38 loss: 3.0619e+00\n",
            "iter: 39 loss: 3.0077e+00\n",
            "iter: 40 loss: 2.9725e+00\n",
            "iter: 41 loss: 2.9474e+00\n",
            "iter: 42 loss: 2.9413e+00\n",
            "iter: 43 loss: 2.9162e+00\n",
            "iter: 44 loss: 2.8577e+00\n",
            "iter: 45 loss: 2.8307e+00\n",
            "iter: 46 loss: 2.7918e+00\n",
            "iter: 47 loss: 2.7341e+00\n",
            "iter: 48 loss: 2.6892e+00\n",
            "iter: 49 loss: 2.6670e+00\n",
            "iter: 50 loss: 2.6593e+00\n",
            "iter: 51 loss: 2.6335e+00\n",
            "iter: 52 loss: 2.5929e+00\n",
            "iter: 53 loss: 2.5607e+00\n",
            "iter: 54 loss: 2.5346e+00\n",
            "iter: 55 loss: 2.5083e+00\n",
            "iter: 56 loss: 2.4842e+00\n",
            "iter: 57 loss: 2.4864e+00\n",
            "iter: 58 loss: 2.4777e+00\n",
            "iter: 59 loss: 2.4251e+00\n",
            "iter: 60 loss: 2.3965e+00\n",
            "iter: 61 loss: 2.3851e+00\n",
            "iter: 62 loss: 2.3658e+00\n",
            "iter: 63 loss: 2.3735e+00\n",
            "iter: 64 loss: 2.3728e+00\n",
            "iter: 65 loss: 2.3646e+00\n",
            "iter: 66 loss: 2.3350e+00\n",
            "iter: 67 loss: 2.3347e+00\n",
            "iter: 68 loss: 2.3203e+00\n",
            "iter: 69 loss: 2.3245e+00\n",
            "iter: 70 loss: 2.3028e+00\n",
            "iter: 71 loss: 2.2812e+00\n",
            "iter: 72 loss: 2.2964e+00\n",
            "iter: 73 loss: 2.2993e+00\n",
            "iter: 74 loss: 2.3280e+00\n",
            "iter: 75 loss: 2.3168e+00\n",
            "iter: 76 loss: 2.3192e+00\n",
            "iter: 77 loss: 2.2933e+00\n",
            "iter: 78 loss: 2.2879e+00\n",
            "iter: 79 loss: 2.2833e+00\n",
            "iter: 80 loss: 2.3160e+00\n",
            "iter: 81 loss: 2.3138e+00\n",
            "iter: 82 loss: 2.3043e+00\n",
            "iter: 83 loss: 2.2955e+00\n",
            "iter: 84 loss: 2.2988e+00\n",
            "iter: 85 loss: 2.3089e+00\n",
            "iter: 86 loss: 2.2952e+00\n",
            "iter: 87 loss: 2.2885e+00\n",
            "iter: 88 loss: 2.2799e+00\n",
            "iter: 89 loss: 2.2773e+00\n",
            "iter: 90 loss: 2.2670e+00\n",
            "iter: 91 loss: 2.2602e+00\n",
            "iter: 92 loss: 2.2553e+00\n",
            "iter: 93 loss: 2.2434e+00\n",
            "iter: 94 loss: 2.2414e+00\n",
            "iter: 95 loss: 2.2366e+00\n",
            "iter: 96 loss: 2.2323e+00\n",
            "iter: 97 loss: 2.2230e+00\n",
            "iter: 98 loss: 2.1983e+00\n",
            "iter: 99 loss: 2.2081e+00\n",
            "=== Evaluate the performance ====\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100% 233M/233M [00:04<00:00, 54.0MB/s]\n",
            "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "i, 0\n",
            "0 PSNR: 12.386 SSIM: 0.505 Jaccard 0.000\n",
            "i, 1\n",
            "1 PSNR: 12.418 SSIM: 0.280 Jaccard 0.000\n",
            "i, 2\n",
            "2 PSNR: 11.267 SSIM: 0.415 Jaccard 0.000\n",
            "i, 3\n",
            "3 PSNR: 11.994 SSIM: 0.291 Jaccard 0.000\n",
            "PSNR: 12.016 SSIM: 0.373 Jaccard 0.000 Lpips 0.666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 attack_fedavg.py"
      ],
      "metadata": {
        "id": "CRjA1VExYsua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5c29cc-5b07-48ca-acb8-89e1e48cb712"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "T_max               : 100\n",
            "batch_size          : 4\n",
            "channels            : 3\n",
            "compress            : none\n",
            "denoiser            : model_zoos/denoiser.pth\n",
            "device              : cuda\n",
            "dpsnr               : -20\n",
            "fed_lr              : 0.0001\n",
            "fedalg              : fedavg\n",
            "gpu                 : [0]\n",
            "half                : False\n",
            "joint_postmodel     : model_zoos/postmodel.pth\n",
            "kernel              : model_zoos/kernels_bicubicx234.mat\n",
            "model               : lenet\n",
            "noise_level         : 0.01\n",
            "num_classes         : 2\n",
            "output_folder       : experiments\n",
            "printevery          : 1\n",
            "refine              : False\n",
            "rog_lr              : 0.05\n",
            "sample_size         : [128, 128]\n",
            "sf                  : 4\n",
            "tau                 : 5\n",
            "test_data_dir       : data\n",
            "thres               : 2\n",
            "train_data_dir      : data\n",
            "tresnet             : model_zoos/tresnet.pth\n",
            "usrnet              : model_zoos/usrgan.pth\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "iter: 0 loss: 5.8704e+01\n",
            "iter: 1 loss: 4.7777e+01\n",
            "iter: 2 loss: 4.4380e+01\n",
            "iter: 3 loss: 4.1066e+01\n",
            "iter: 4 loss: 3.4605e+01\n",
            "iter: 5 loss: 3.3327e+01\n",
            "iter: 6 loss: 3.0141e+01\n",
            "iter: 7 loss: 3.0821e+01\n",
            "iter: 8 loss: 2.7072e+01\n",
            "iter: 9 loss: 2.4814e+01\n",
            "iter: 10 loss: 2.5329e+01\n",
            "iter: 11 loss: 2.7585e+01\n",
            "iter: 12 loss: 2.4204e+01\n",
            "iter: 13 loss: 2.3287e+01\n",
            "iter: 14 loss: 2.1989e+01\n",
            "iter: 15 loss: 2.1228e+01\n",
            "iter: 16 loss: 2.0375e+01\n",
            "iter: 17 loss: 1.9088e+01\n",
            "iter: 18 loss: 1.9134e+01\n",
            "iter: 19 loss: 1.8597e+01\n",
            "iter: 20 loss: 1.7810e+01\n",
            "iter: 21 loss: 1.7613e+01\n",
            "iter: 22 loss: 1.7302e+01\n",
            "iter: 23 loss: 1.6431e+01\n",
            "iter: 24 loss: 1.6523e+01\n",
            "iter: 25 loss: 1.7145e+01\n",
            "iter: 26 loss: 1.7189e+01\n",
            "iter: 27 loss: 1.6511e+01\n",
            "iter: 28 loss: 1.6003e+01\n",
            "iter: 29 loss: 1.6120e+01\n",
            "iter: 30 loss: 1.6192e+01\n",
            "iter: 31 loss: 1.6626e+01\n",
            "iter: 32 loss: 1.6521e+01\n",
            "iter: 33 loss: 1.5714e+01\n",
            "iter: 34 loss: 1.5474e+01\n",
            "iter: 35 loss: 1.4591e+01\n",
            "iter: 36 loss: 1.4746e+01\n",
            "iter: 37 loss: 1.4724e+01\n",
            "iter: 38 loss: 1.4915e+01\n",
            "iter: 39 loss: 1.5180e+01\n",
            "iter: 40 loss: 1.4216e+01\n",
            "iter: 41 loss: 1.3923e+01\n",
            "iter: 42 loss: 1.3930e+01\n",
            "iter: 43 loss: 1.3989e+01\n",
            "iter: 44 loss: 1.3960e+01\n",
            "iter: 45 loss: 1.4060e+01\n",
            "iter: 46 loss: 1.3897e+01\n",
            "iter: 47 loss: 1.3968e+01\n",
            "iter: 48 loss: 1.3945e+01\n",
            "iter: 49 loss: 1.3717e+01\n",
            "iter: 50 loss: 1.3122e+01\n",
            "iter: 51 loss: 1.2700e+01\n",
            "iter: 52 loss: 1.2721e+01\n",
            "iter: 53 loss: 1.2660e+01\n",
            "iter: 54 loss: 1.2414e+01\n",
            "iter: 55 loss: 1.2468e+01\n",
            "iter: 56 loss: 1.2445e+01\n",
            "iter: 57 loss: 1.2598e+01\n",
            "iter: 58 loss: 1.2930e+01\n",
            "iter: 59 loss: 1.3054e+01\n",
            "iter: 60 loss: 1.2799e+01\n",
            "iter: 61 loss: 1.2724e+01\n",
            "iter: 62 loss: 1.2587e+01\n",
            "iter: 63 loss: 1.2525e+01\n",
            "iter: 64 loss: 1.2530e+01\n",
            "iter: 65 loss: 1.2530e+01\n",
            "iter: 66 loss: 1.2527e+01\n",
            "iter: 67 loss: 1.2447e+01\n",
            "iter: 68 loss: 1.2450e+01\n",
            "iter: 69 loss: 1.2262e+01\n",
            "iter: 70 loss: 1.2211e+01\n",
            "iter: 71 loss: 1.2139e+01\n",
            "iter: 72 loss: 1.2005e+01\n",
            "iter: 73 loss: 1.1985e+01\n",
            "iter: 74 loss: 1.1788e+01\n",
            "iter: 75 loss: 1.1632e+01\n",
            "iter: 76 loss: 1.1718e+01\n",
            "iter: 77 loss: 1.1939e+01\n",
            "iter: 78 loss: 1.2052e+01\n",
            "iter: 79 loss: 1.2062e+01\n",
            "iter: 80 loss: 1.2079e+01\n",
            "iter: 81 loss: 1.2075e+01\n",
            "iter: 82 loss: 1.2076e+01\n",
            "iter: 83 loss: 1.2154e+01\n",
            "iter: 84 loss: 1.2182e+01\n",
            "iter: 85 loss: 1.2139e+01\n",
            "iter: 86 loss: 1.2162e+01\n",
            "iter: 87 loss: 1.2218e+01\n",
            "iter: 88 loss: 1.2279e+01\n",
            "iter: 89 loss: 1.2258e+01\n",
            "iter: 90 loss: 1.2238e+01\n",
            "iter: 91 loss: 1.2219e+01\n",
            "iter: 92 loss: 1.2209e+01\n",
            "iter: 93 loss: 1.2051e+01\n",
            "iter: 94 loss: 1.1825e+01\n",
            "iter: 95 loss: 1.1747e+01\n",
            "iter: 96 loss: 1.1782e+01\n",
            "iter: 97 loss: 1.1795e+01\n",
            "iter: 98 loss: 1.1877e+01\n",
            "iter: 99 loss: 1.1965e+01\n",
            "=== Evaluate the performance ====\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "i, 0\n",
            "0 PSNR: 13.063 SSIM: 0.689 Jaccard 0.000\n",
            "i, 1\n",
            "1 PSNR: 12.666 SSIM: 0.475 Jaccard 0.000\n",
            "i, 2\n",
            "2 PSNR: 11.624 SSIM: 0.569 Jaccard 0.000\n",
            "i, 3\n",
            "3 PSNR: 11.991 SSIM: 0.498 Jaccard 0.000\n",
            "PSNR: 12.336 SSIM: 0.558 Jaccard 0.000 Lpips 0.445\n"
          ]
        }
      ]
    }
  ]
}