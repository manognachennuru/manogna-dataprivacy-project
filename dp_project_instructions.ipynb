{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code snippet mounts the drive onto the colab. Make sure you connect to the T4 GPU runtime, because our code will not work on CPUs (because of NVDIA CUDA)"
      ],
      "metadata": {
        "id": "HgQ2ONCCIxci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRkQjjsO1Ind",
        "outputId": "daea5cfe-5ff1-4f20-b327-71c26742b507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below text only when you're running the code first time. to clone the github repo (https://github.com/KAI-YUE/rog.git by authors of the research paper) into your own drive."
      ],
      "metadata": {
        "id": "Mz_HLxwsJB-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE THE COMMENTS WHEN RUNNING FOR THE FIRST TIME.\n",
        "# %%bash\n",
        "# cd /content/drive/MyDrive/\n",
        "# mkdir -p dp-project-2\n",
        "# cd dp-project-2\n",
        "# git clone https://github.com/KAI-YUE/rog.git"
      ],
      "metadata": {
        "id": "du8rh6Zy1cQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below coding snippet is to change the current working directory to the home directory"
      ],
      "metadata": {
        "id": "htw_w99dTWIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Working Directory at the beginning\", end = \"\")\n",
        "!pwd\n",
        "\n",
        "import os\n",
        "# Define the path to the directory where your data is located\n",
        "home_directory = \"/content/drive/MyDrive/dp-project-2/rog\"\n",
        "\n",
        "# Change the current directory to the data directory\n",
        "os.chdir(home_directory)\n",
        "\n",
        "print(\"Working Directory\", end = \"\")\n",
        "!pwd"
      ],
      "metadata": {
        "id": "z1nVchi52Sg3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a64803-6e73-48b1-da70-2ae3ef9d7461"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working Directory at the beginning/content/drive/MyDrive/dp-project-2/rog\n",
            "Working Directory/content/drive/MyDrive/dp-project-2/rog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Python packages. This will be done in next few cells. Some of them are done using requirements.txt. I put seperate statements for those that are not installed using requirements.\n",
        "Ignore the error in requirements.txt"
      ],
      "metadata": {
        "id": "5VNEQ3g4sdYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "metadata": {
        "id": "BNobgpcK2dBg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b5c787-fc84-430b-bb68-b073e67d0d4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting inplace_abn==1.1.0 (from -r requirements.txt (line 1))\n",
            "  Downloading inplace-abn-1.1.0.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lpips==0.1.4 (from -r requirements.txt (line 2))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.19.5 (from -r requirements.txt (line 3))\n",
            "  Downloading numpy-1.19.5.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv_python==4.5.2.52 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv_python==4.5.2.52\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install inplace-abn"
      ],
      "metadata": {
        "id": "OW74CoqIZdas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2573b1-4f8b-4705-bc06-bff2c02ce526"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting inplace-abn\n",
            "  Using cached inplace-abn-1.1.0.tar.gz (137 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: inplace-abn\n",
            "  Building wheel for inplace-abn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inplace-abn: filename=inplace_abn-1.1.0-cp310-cp310-linux_x86_64.whl size=4199514 sha256=1a5ee3a21278834c4c3e1ec5b75a52491f44ed7ddc0e5088c95531b8a0f91bbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/f2/05/97ab74dbf2ed6d592684f76d0ae8f33f66bbafa0ec5b53b416\n",
            "Successfully built inplace-abn\n",
            "Installing collected packages: inplace-abn\n",
            "Successfully installed inplace-abn-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lpips"
      ],
      "metadata": {
        "id": "pNpXorYBaf3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "506cf44e-5bf6-4e65-bcc7-53348c255609"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lpips\n",
            "  Using cached lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from lpips) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (1.11.4)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from lpips) (4.66.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.0->lpips) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.0->lpips)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.2.1->lpips) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.0->lpips) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.0->lpips) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lpips\n",
            "Successfully installed lpips-0.1.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code is just to see if all the dependencies are installed properly. I put them in try-except blocks so that it won't raise an error. It instead prints a statement if the respective package is not installed."
      ],
      "metadata": {
        "id": "WLPA_PL3s2Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import inplace_abn\n",
        "    print(\"inplace_abn version:\", inplace_abn.__version__)\n",
        "except ImportError:\n",
        "    print(\"inplace_abn is not installed\")\n",
        "\n",
        "try:\n",
        "    import lpips\n",
        "    print(\"lpips installed\")\n",
        "except ImportError:\n",
        "    print(\"lpips is not installed\")\n",
        "\n",
        "try:\n",
        "    import numpy\n",
        "    print(\"numpy version:\", numpy.__version__)\n",
        "except ImportError:\n",
        "    print(\"numpy is not installed\")\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "    print(\"opencv-python version:\", cv2.__version__)  # OpenCV is often imported as cv2\n",
        "except ImportError:\n",
        "    print(\"opencv-python is not installed\")\n",
        "\n",
        "try:\n",
        "    import pandas\n",
        "    print(\"pandas version:\", pandas.__version__)\n",
        "except ImportError:\n",
        "    print(\"pandas is not installed\")\n",
        "\n",
        "try:\n",
        "    import PIL\n",
        "    print(\"Pillow version:\", PIL.__version__)\n",
        "except ImportError:\n",
        "    print(\"Pillow is not installed\")\n",
        "\n",
        "try:\n",
        "    import yaml\n",
        "    print(\"PyYAML version:\", yaml.__version__)\n",
        "except ImportError:\n",
        "    print(\"PyYAML is not installed\")\n",
        "\n",
        "try:\n",
        "    import scipy\n",
        "    print(\"scipy version:\", scipy.__version__)\n",
        "except ImportError:\n",
        "    print(\"scipy is not installed\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "except ImportError:\n",
        "    print(\"PyTorch is not installed\")\n",
        "\n",
        "try:\n",
        "    import torchvision\n",
        "    print(\"torchvision version:\", torchvision.__version__)\n",
        "except ImportError:\n",
        "    print(\"torchvision is not installed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUqYWzmGMqIl",
        "outputId": "c7bdab58-e3e0-4608-bea3-f0ea97447639"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inplace_abn version: 1.1.0\n",
            "lpips installed\n",
            "numpy version: 1.25.2\n",
            "opencv-python version: 4.8.0\n",
            "pandas version: 2.0.3\n",
            "Pillow version: 9.4.0\n",
            "PyYAML version: 6.0.1\n",
            "scipy version: 1.11.4\n",
            "PyTorch version: 2.2.1+cu121\n",
            "torchvision version: 0.17.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below cell is to download the pretrained models and put them under model_zoos [link](https://huggingface.co/erickyue/rog_modelzoo/tree/main)\n",
        "\n",
        "Along with downloading, i used bash commands to move the files into the right folder."
      ],
      "metadata": {
        "id": "-bp0JLx1tJTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE UNCOMMENT IF YOU\"RE RUNNING IT FOR THE FIRST TIME\n",
        "#run the following only if you're doing it for the first time\n",
        "#\n",
        "\n",
        "# import os\n",
        "# os.chdir(\"/content/drive/MyDrive/dp-project-2/rog/model_zoos\")\n",
        "\n",
        "# !pwd\n",
        "\n",
        "# !apt install git-lfs\n",
        "# !git lfs install\n",
        "\n",
        "# !git clone https://huggingface.co/erickyue/rog_modelzoo\n",
        "\n",
        "\n",
        "# !mv -v /content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/*  ./\n",
        "# !rm -rf rog_modelzoo/"
      ],
      "metadata": {
        "id": "H2K8wZyAElpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b61a7d3-5860-4eab-bdf7-956ed9a2e7b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dp-project-2/rog/model_zoos\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'rog_modelzoo'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 11\u001b[K\n",
            "Unpacking objects: 100% (11/11), 8.51 KiB | 52.00 KiB/s, done.\n",
            "Filtering content: 100% (4/4), 747.60 MiB | 42.23 MiB/s, done.\n",
            "fatal: cannot exec '/content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/.git/hooks/post-checkout': Permission denied\n",
            "renamed '/content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/denoiser.pth' -> './denoiser.pth'\n",
            "renamed '/content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/kernels_bicubicx234.mat' -> './kernels_bicubicx234.mat'\n",
            "renamed '/content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/postmodel.pth' -> './postmodel.pth'\n",
            "renamed '/content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/README.md' -> './README.md'\n",
            "renamed '/content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/tresnet.pth' -> './tresnet.pth'\n",
            "renamed '/content/drive/MyDrive/dp-project-2/rog/model_zoos/rog_modelzoo/usrgan.pth' -> './usrgan.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below snippet is to put the csv folder at the right location.\n",
        "\n",
        "Download the csv file (https://storage.googleapis.com/openimages/v6/oidv6-class-descriptions.csv) and put it under data folder\n",
        "\n",
        "\n",
        "For the chest X-ray dataset, there are only two labels. thus the excel sheet has only two columns."
      ],
      "metadata": {
        "id": "f8_aLM5OtnRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import shutil\n",
        "# from google.colab import files\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Get the file name\n",
        "# file_name = next(iter(uploaded))\n",
        "\n",
        "# # Define the destination directory\n",
        "# destination_dir = \"/content/drive/MyDrive/dp-project-2/rog/data\"\n",
        "\n",
        "# # Move the uploaded file to the destination directory\n",
        "# shutil.move(file_name, destination_dir)\n",
        "\n",
        "# # Print the path of the moved file\n",
        "# moved_file_path = destination_dir + \"/\" + file_name\n",
        "# print(f\"Moved file to: {moved_file_path}\")\n",
        "\n",
        "\n",
        "# # upload the csv file here"
      ],
      "metadata": {
        "id": "Dtt77f_1FBGZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The whole data is accessed using a datapair.dat\n",
        "I deleted the old datapair and created the datapair.dat for the chest X-ray dataset."
      ],
      "metadata": {
        "id": "Xod51qtGuByw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code to replace old datapair.dat to new datapair.dat\n",
        "#!mv /content/drive/MyDrive/chest_xray_dataset/datapair.dat /content/drive/MyDrive/dp-project-2/rog/data/datapair.dat\n",
        "\n",
        "#!mv /content/drive/SharedFolder/chest_xray_dataset/datapair.dat /content/drive/MyDrive/dp-project-2/rog/data/datapair.dat\n"
      ],
      "metadata": {
        "id": "kVuq4mKrSXQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#here add shortcut to the shared folder and save it in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "eTEziKnpouQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code snippet changes the active directory. It is needed to avoid path conflicts later on."
      ],
      "metadata": {
        "id": "VmuTapAeufph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory where your data is located\n",
        "data_directory = \"/content/drive/MyDrive/dp-project-2/rog\"\n",
        "\n",
        "# Change the current directory to the data directory\n",
        "os.chdir(data_directory)\n",
        "\n",
        "!pwd"
      ],
      "metadata": {
        "id": "4Ar45suOJWmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f789a1ff-1eed-4f37-ecab-ab2dd1c8f3f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dp-project-2/rog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code snippet prints some of the contents of datapair.dat"
      ],
      "metadata": {
        "id": "Tma0a8LGuWSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code to print some of the contents of datapair.dat\n",
        "\n",
        "datapair_file_path = \"data/datapair.dat\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Load the datapair from the file\n",
        "with open(datapair_file_path, \"rb\") as fp:\n",
        "    record = pickle.load(fp)\n",
        "\n",
        "# Print the datapair\n",
        "print(\"datapair:\")\n",
        "for index, item in enumerate(record[\"data_pair\"]):\n",
        "    print(f\"Index {index}: {item}\")\n",
        "    if index == 10:\n",
        "      break\n",
        "\n",
        "# Check if 'root' key exists and print it if it does\n",
        "if \"root\" in record:\n",
        "    print(f\"Root directory: {record['root']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrMibKyqPMBE",
        "outputId": "4db7c9c7-8d66-46b0-d076-65617f05a0d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datapair:\n",
            "Index 0: ('NORMAL', 'IM-0533-0001-0001.jpeg', 0)\n",
            "Index 1: ('NORMAL', 'IM-0533-0001-0002.jpeg', 0)\n",
            "Index 2: ('NORMAL', 'IM-0526-0001.jpeg', 0)\n",
            "Index 3: ('NORMAL', 'IM-0534-0001.jpeg', 0)\n",
            "Index 4: ('NORMAL', 'IM-0522-0001.jpeg', 0)\n",
            "Index 5: ('NORMAL', 'IM-0532-0001.jpeg', 0)\n",
            "Index 6: ('NORMAL', 'IM-0537-0001.jpeg', 0)\n",
            "Index 7: ('NORMAL', 'IM-0533-0001.jpeg', 0)\n",
            "Index 8: ('NORMAL', 'IM-0524-0001.jpeg', 0)\n",
            "Index 9: ('NORMAL', 'IM-0535-0001.jpeg', 0)\n",
            "Index 10: ('NORMAL', 'IM-0523-0001-0003.jpeg', 0)\n",
            "Root directory: /content/drive/MyDrive/chest_xray_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "change config to reflect the new number of classes\n",
        "I might also need to fine tune some of the parameters inorder to achieve better results.\n"
      ],
      "metadata": {
        "id": "RW62UcKLRJNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#change them at this point"
      ],
      "metadata": {
        "id": "vl5W-nU6vgAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the example with QSGD: Run the following main.py file"
      ],
      "metadata": {
        "id": "DHxhhWSququf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py"
      ],
      "metadata": {
        "id": "xkZBLfizFrS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d8afa5-3434-4f6c-bc22-864c9a800423"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "T_max               : 100\n",
            "batch_size          : 4\n",
            "channels            : 3\n",
            "compress            : none\n",
            "denoiser            : model_zoos/denoiser.pth\n",
            "device              : cuda\n",
            "dpsnr               : -20\n",
            "fed_lr              : 0.0001\n",
            "fedalg              : fedavg\n",
            "gpu                 : [0]\n",
            "half                : False\n",
            "joint_postmodel     : model_zoos/postmodel.pth\n",
            "kernel              : model_zoos/kernels_bicubicx234.mat\n",
            "model               : resnet18\n",
            "noise_level         : 0.01\n",
            "num_classes         : 2\n",
            "output_folder       : experiments\n",
            "printevery          : 1\n",
            "refine              : False\n",
            "rog_lr              : 0.05\n",
            "sample_size         : [128, 128]\n",
            "sf                  : 4\n",
            "tau                 : 10\n",
            "test_data_dir       : data\n",
            "thres               : 2\n",
            "train_data_dir      : data\n",
            "tresnet             : model_zoos/tresnet.pth\n",
            "usrnet              : model_zoos/usrgan.pth\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/content/drive/MyDrive/dp-project-2/rog/networks/metanet.py:81: UserWarning: Patching for module <class 'networks.resnet.BasicBlock'> is not implemented.\n",
            "  warnings.warn(f'Patching for module {module.__class__} is not implemented.')\n",
            "iter: 0 loss: 1.8694e+01\n",
            "iter: 1 loss: 1.3981e+01\n",
            "iter: 2 loss: 1.1985e+01\n",
            "iter: 3 loss: 1.0963e+01\n",
            "iter: 4 loss: 1.0258e+01\n",
            "iter: 5 loss: 9.3696e+00\n",
            "iter: 6 loss: 8.5993e+00\n",
            "iter: 7 loss: 8.0358e+00\n",
            "iter: 8 loss: 7.4068e+00\n",
            "iter: 9 loss: 7.0150e+00\n",
            "iter: 10 loss: 6.6918e+00\n",
            "iter: 11 loss: 6.4656e+00\n",
            "iter: 12 loss: 6.1859e+00\n",
            "iter: 13 loss: 5.9127e+00\n",
            "iter: 14 loss: 5.5325e+00\n",
            "iter: 15 loss: 5.3153e+00\n",
            "iter: 16 loss: 5.0824e+00\n",
            "iter: 17 loss: 4.8093e+00\n",
            "iter: 18 loss: 4.6913e+00\n",
            "iter: 19 loss: 4.5643e+00\n",
            "iter: 20 loss: 4.4525e+00\n",
            "iter: 21 loss: 4.2745e+00\n",
            "iter: 22 loss: 4.1668e+00\n",
            "iter: 23 loss: 4.0126e+00\n",
            "iter: 24 loss: 4.0059e+00\n",
            "iter: 25 loss: 3.9649e+00\n",
            "iter: 26 loss: 3.8184e+00\n",
            "iter: 27 loss: 3.8195e+00\n",
            "iter: 28 loss: 3.8603e+00\n",
            "iter: 29 loss: 3.7367e+00\n",
            "iter: 30 loss: 3.6259e+00\n",
            "iter: 31 loss: 3.4803e+00\n",
            "iter: 32 loss: 3.3817e+00\n",
            "iter: 33 loss: 3.3728e+00\n",
            "iter: 34 loss: 3.2605e+00\n",
            "iter: 35 loss: 3.1483e+00\n",
            "iter: 36 loss: 3.0780e+00\n",
            "iter: 37 loss: 3.0213e+00\n",
            "iter: 38 loss: 3.0072e+00\n",
            "iter: 39 loss: 2.9593e+00\n",
            "iter: 40 loss: 2.9222e+00\n",
            "iter: 41 loss: 2.8732e+00\n",
            "iter: 42 loss: 2.8512e+00\n",
            "iter: 43 loss: 2.8506e+00\n",
            "iter: 44 loss: 2.7649e+00\n",
            "iter: 45 loss: 2.7325e+00\n",
            "iter: 46 loss: 2.7136e+00\n",
            "iter: 47 loss: 2.6730e+00\n",
            "iter: 48 loss: 2.6298e+00\n",
            "iter: 49 loss: 2.6325e+00\n",
            "iter: 50 loss: 2.5927e+00\n",
            "iter: 51 loss: 2.5818e+00\n",
            "iter: 52 loss: 2.5443e+00\n",
            "iter: 53 loss: 2.5470e+00\n",
            "iter: 54 loss: 2.5254e+00\n",
            "iter: 55 loss: 2.5071e+00\n",
            "iter: 56 loss: 2.4970e+00\n",
            "iter: 57 loss: 2.4780e+00\n",
            "iter: 58 loss: 2.4695e+00\n",
            "iter: 59 loss: 2.4831e+00\n",
            "iter: 60 loss: 2.4389e+00\n",
            "iter: 61 loss: 2.4478e+00\n",
            "iter: 62 loss: 2.4408e+00\n",
            "iter: 63 loss: 2.4376e+00\n",
            "iter: 64 loss: 2.4333e+00\n",
            "iter: 65 loss: 2.4006e+00\n",
            "iter: 66 loss: 2.3891e+00\n",
            "iter: 67 loss: 2.3807e+00\n",
            "iter: 68 loss: 2.3680e+00\n",
            "iter: 69 loss: 2.3548e+00\n",
            "iter: 70 loss: 2.3714e+00\n",
            "iter: 71 loss: 2.3675e+00\n",
            "iter: 72 loss: 2.3658e+00\n",
            "iter: 73 loss: 2.3767e+00\n",
            "iter: 74 loss: 2.3856e+00\n",
            "iter: 75 loss: 2.3868e+00\n",
            "iter: 76 loss: 2.3872e+00\n",
            "iter: 77 loss: 2.3493e+00\n",
            "iter: 78 loss: 2.3386e+00\n",
            "iter: 79 loss: 2.3381e+00\n",
            "iter: 80 loss: 2.3263e+00\n",
            "iter: 81 loss: 2.3350e+00\n",
            "iter: 82 loss: 2.3182e+00\n",
            "iter: 83 loss: 2.3134e+00\n",
            "iter: 84 loss: 2.3071e+00\n",
            "iter: 85 loss: 2.3154e+00\n",
            "iter: 86 loss: 2.3129e+00\n",
            "iter: 87 loss: 2.3065e+00\n",
            "iter: 88 loss: 2.3113e+00\n",
            "iter: 89 loss: 2.2969e+00\n",
            "iter: 90 loss: 2.2966e+00\n",
            "iter: 91 loss: 2.2939e+00\n",
            "iter: 92 loss: 2.3003e+00\n",
            "iter: 93 loss: 2.3058e+00\n",
            "iter: 94 loss: 2.3086e+00\n",
            "iter: 95 loss: 2.3167e+00\n",
            "iter: 96 loss: 2.3064e+00\n",
            "iter: 97 loss: 2.2896e+00\n",
            "iter: 98 loss: 2.2864e+00\n",
            "iter: 99 loss: 2.2886e+00\n",
            "=== Evaluate the performance ====\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100% 233M/233M [00:02<00:00, 115MB/s]\n",
            "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "i, 0\n",
            "0 PSNR: 11.508 SSIM: 0.397 Jaccard 0.000\n",
            "i, 1\n",
            "1 PSNR: 12.485 SSIM: 0.225 Jaccard 0.000\n",
            "i, 2\n",
            "2 PSNR: 11.099 SSIM: 0.363 Jaccard 0.000\n",
            "i, 3\n",
            "3 PSNR: 11.672 SSIM: 0.217 Jaccard 0.000\n",
            "PSNR: 11.691 SSIM: 0.300 Jaccard 0.000 Lpips 0.669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below snippet runs the example with FedAvg:\n",
        "Here the results will be stored under experiments.\n",
        "\n",
        "PSNR, SSM and LPIPS of the results are evaluated and printed too.\n",
        "\n",
        "We can also see original and reconstructed images (for minumum runnable image set) to see the results."
      ],
      "metadata": {
        "id": "LeYjV43Ju0Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/dp-project-2/rog/attack_fedavg.py"
      ],
      "metadata": {
        "id": "CRjA1VExYsua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c3a38f5-aab1-4123-e93a-9c70d1897fd9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "T_max               : 100\n",
            "batch_size          : 4\n",
            "channels            : 3\n",
            "compress            : none\n",
            "denoiser            : model_zoos/denoiser.pth\n",
            "device              : cuda\n",
            "dpsnr               : -20\n",
            "fed_lr              : 0.0001\n",
            "fedalg              : fedavg\n",
            "gpu                 : [0]\n",
            "half                : False\n",
            "joint_postmodel     : model_zoos/postmodel.pth\n",
            "kernel              : model_zoos/kernels_bicubicx234.mat\n",
            "model               : lenet\n",
            "noise_level         : 0.01\n",
            "num_classes         : 2\n",
            "output_folder       : experiments\n",
            "printevery          : 1\n",
            "refine              : False\n",
            "rog_lr              : 0.05\n",
            "sample_size         : [128, 128]\n",
            "sf                  : 4\n",
            "tau                 : 5\n",
            "test_data_dir       : data\n",
            "thres               : 2\n",
            "train_data_dir      : data\n",
            "tresnet             : model_zoos/tresnet.pth\n",
            "usrnet              : model_zoos/usrgan.pth\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "iter: 0 loss: 5.9759e+01\n",
            "iter: 1 loss: 4.6577e+01\n",
            "iter: 2 loss: 4.4544e+01\n",
            "iter: 3 loss: 4.1682e+01\n",
            "iter: 4 loss: 4.2019e+01\n",
            "iter: 5 loss: 3.7074e+01\n",
            "iter: 6 loss: 3.6139e+01\n",
            "iter: 7 loss: 3.3525e+01\n",
            "iter: 8 loss: 2.8644e+01\n",
            "iter: 9 loss: 2.6692e+01\n",
            "iter: 10 loss: 2.6307e+01\n",
            "iter: 11 loss: 2.5809e+01\n",
            "iter: 12 loss: 2.4384e+01\n",
            "iter: 13 loss: 2.3452e+01\n",
            "iter: 14 loss: 2.3437e+01\n",
            "iter: 15 loss: 2.1091e+01\n",
            "iter: 16 loss: 2.1066e+01\n",
            "iter: 17 loss: 2.0404e+01\n",
            "iter: 18 loss: 1.9664e+01\n",
            "iter: 19 loss: 1.8540e+01\n",
            "iter: 20 loss: 1.8736e+01\n",
            "iter: 21 loss: 1.8759e+01\n",
            "iter: 22 loss: 1.7987e+01\n",
            "iter: 23 loss: 1.9057e+01\n",
            "iter: 24 loss: 1.8854e+01\n",
            "iter: 25 loss: 1.9006e+01\n",
            "iter: 26 loss: 1.8693e+01\n",
            "iter: 27 loss: 1.8696e+01\n",
            "iter: 28 loss: 1.8454e+01\n",
            "iter: 29 loss: 1.7945e+01\n",
            "iter: 30 loss: 1.7369e+01\n",
            "iter: 31 loss: 1.7631e+01\n",
            "iter: 32 loss: 1.7196e+01\n",
            "iter: 33 loss: 1.6976e+01\n",
            "iter: 34 loss: 1.6643e+01\n",
            "iter: 35 loss: 1.6344e+01\n",
            "iter: 36 loss: 1.5937e+01\n",
            "iter: 37 loss: 1.5533e+01\n",
            "iter: 38 loss: 1.5605e+01\n",
            "iter: 39 loss: 1.4946e+01\n",
            "iter: 40 loss: 1.5133e+01\n",
            "iter: 41 loss: 1.5031e+01\n",
            "iter: 42 loss: 1.4798e+01\n",
            "iter: 43 loss: 1.4308e+01\n",
            "iter: 44 loss: 1.4206e+01\n",
            "iter: 45 loss: 1.4013e+01\n",
            "iter: 46 loss: 1.4009e+01\n",
            "iter: 47 loss: 1.4018e+01\n",
            "iter: 48 loss: 1.4042e+01\n",
            "iter: 49 loss: 1.3946e+01\n",
            "iter: 50 loss: 1.3907e+01\n",
            "iter: 51 loss: 1.3921e+01\n",
            "iter: 52 loss: 1.3820e+01\n",
            "iter: 53 loss: 1.3841e+01\n",
            "iter: 54 loss: 1.3913e+01\n",
            "iter: 55 loss: 1.3690e+01\n",
            "iter: 56 loss: 1.3728e+01\n",
            "iter: 57 loss: 1.3836e+01\n",
            "iter: 58 loss: 1.3796e+01\n",
            "iter: 59 loss: 1.3819e+01\n",
            "iter: 60 loss: 1.3799e+01\n",
            "iter: 61 loss: 1.3646e+01\n",
            "iter: 62 loss: 1.3534e+01\n",
            "iter: 63 loss: 1.3368e+01\n",
            "iter: 64 loss: 1.3332e+01\n",
            "iter: 65 loss: 1.3188e+01\n",
            "iter: 66 loss: 1.3369e+01\n",
            "iter: 67 loss: 1.3370e+01\n",
            "iter: 68 loss: 1.3364e+01\n",
            "iter: 69 loss: 1.3353e+01\n",
            "iter: 70 loss: 1.3393e+01\n",
            "iter: 71 loss: 1.3278e+01\n",
            "iter: 72 loss: 1.3185e+01\n",
            "iter: 73 loss: 1.3081e+01\n",
            "iter: 74 loss: 1.3107e+01\n",
            "iter: 75 loss: 1.3272e+01\n",
            "iter: 76 loss: 1.3221e+01\n",
            "iter: 77 loss: 1.3279e+01\n",
            "iter: 78 loss: 1.3396e+01\n",
            "iter: 79 loss: 1.3439e+01\n",
            "iter: 80 loss: 1.3380e+01\n",
            "iter: 81 loss: 1.3366e+01\n",
            "iter: 82 loss: 1.3453e+01\n",
            "iter: 83 loss: 1.3421e+01\n",
            "iter: 84 loss: 1.3275e+01\n",
            "iter: 85 loss: 1.3283e+01\n",
            "iter: 86 loss: 1.3199e+01\n",
            "iter: 87 loss: 1.3196e+01\n",
            "iter: 88 loss: 1.3192e+01\n",
            "iter: 89 loss: 1.3196e+01\n",
            "iter: 90 loss: 1.2975e+01\n",
            "iter: 91 loss: 1.2925e+01\n",
            "iter: 92 loss: 1.2941e+01\n",
            "iter: 93 loss: 1.2915e+01\n",
            "iter: 94 loss: 1.2932e+01\n",
            "iter: 95 loss: 1.2837e+01\n",
            "iter: 96 loss: 1.2809e+01\n",
            "iter: 97 loss: 1.2805e+01\n",
            "iter: 98 loss: 1.2714e+01\n",
            "iter: 99 loss: 1.2603e+01\n",
            "=== Evaluate the performance ====\n",
            "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Loading model from: /usr/local/lib/python3.10/dist-packages/lpips/weights/v0.1/alex.pth\n",
            "i, 0\n",
            "0 PSNR: 12.642 SSIM: 0.642 Jaccard 0.000\n",
            "i, 1\n",
            "1 PSNR: 12.819 SSIM: 0.463 Jaccard 0.000\n",
            "i, 2\n",
            "2 PSNR: 11.122 SSIM: 0.522 Jaccard 0.000\n",
            "i, 3\n",
            "3 PSNR: 10.661 SSIM: 0.381 Jaccard 0.000\n",
            "PSNR: 11.811 SSIM: 0.502 Jaccard 0.000 Lpips 0.478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTePSSu-i9eB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}