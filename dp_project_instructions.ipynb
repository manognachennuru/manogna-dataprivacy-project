{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions for Running the Code\n",
        "\n",
        "To reproduce the results and execute the code of this repo successfully, please follow these steps:\n",
        "\n",
        "1. Ensure that you are connected to a T4 GPU runtime, as our code relies on NVIDIA CUDA for acceleration and may not work efficiently on CPUs.\n",
        "2. Run the code snippets provided below sequentially.\n",
        "3. Pay attention to any comments within the code snippets.\n",
        "4. After running all code snippets, you can see the evaluation metrics and reconstructed images in experiments folder.\n",
        "\n",
        "Please note: You need to have access to view the [dataset](https://drive.google.com/drive/folders/1mElxNk6-XAfSeJcK76oZuXvU5zAYF7FS?usp=sharing), and since we're running this on Drive, you need to have enough storage space in your Google Drive for this to work."
      ],
      "metadata": {
        "id": "HgQ2ONCCIxci"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRkQjjsO1Ind"
      },
      "outputs": [],
      "source": [
        "# Mounting the Google Drive onto Colab.\n",
        "# Note: Connect to the T4 GPU runtime as our code requires GPU acceleration due to NVIDIA CUDA dependencies.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the following code only when executing it for the first time to clone the GitHub repository into your google drive.\n",
        "\n",
        "# UNCOMMENT THE CODE BELOW WHEN RUNNING FOR THE FIRST TIME.\n",
        "# %%bash\n",
        "# cd /content/drive/MyDrive/\n",
        "# mkdir -p manogna-dp-project\n",
        "# cd manogna-dp-project\n",
        "# git clone https://github.com/manognachennuru/rog.git\n"
      ],
      "metadata": {
        "id": "du8rh6Zy1cQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below coding snippet is to change the current working directory to the home directory"
      ],
      "metadata": {
        "id": "htw_w99dTWIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the current working directory at the beginning\n",
        "print(\"Working Directory at the beginning:\", end=\"\")\n",
        "!pwd\n",
        "\n",
        "import os\n",
        "\n",
        "# Define the path to the directory where your data is located\n",
        "home_directory = \"/content/drive/MyDrive/manogna-dp-project/rog\"\n",
        "\n",
        "# Change the current directory to the data directory\n",
        "os.chdir(home_directory)\n",
        "\n",
        "# Printing the current working directory after changing\n",
        "print(\"Working Directory:\", end=\"\")\n",
        "!pwd\n"
      ],
      "metadata": {
        "id": "z1nVchi52Sg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Python Packages\n",
        "\n",
        "In the following cells, we'll install the required Python packages. Some packages are installed using a `requirements.txt` file, while others will be installed individually. If you encounter any errors during installation, you can safely ignore them unless they prevent the notebook from running successfully.\n",
        "\n",
        "Please proceed to the next cells for package installation.\n"
      ],
      "metadata": {
        "id": "5VNEQ3g4sdYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Python packages\n",
        "# Some packages are installed using requirements.txt. Individual statements are provided for those that are not installed using requirements.\n",
        "# Ignore the error for opencv_python==4.5.2.52 as it seems there's no matching distribution.\n",
        "\n",
        "!pip3 install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "BNobgpcK2dBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install inplace-abn"
      ],
      "metadata": {
        "id": "OW74CoqIZdas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lpips"
      ],
      "metadata": {
        "id": "pNpXorYBaf3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check installations\n",
        "\n",
        " The below code is just to see if all the dependencies are installed properly. I put them in try-except blocks so that it won't raise an error. It instead prints a statement if the respective package is not installed."
      ],
      "metadata": {
        "id": "WLPA_PL3s2Zv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import inplace_abn\n",
        "    print(\"inplace_abn version:\", inplace_abn.__version__)\n",
        "except ImportError:\n",
        "    print(\"inplace_abn is not installed\")\n",
        "\n",
        "try:\n",
        "    import lpips\n",
        "    print(\"lpips installed\")\n",
        "except ImportError:\n",
        "    print(\"lpips is not installed\")\n",
        "\n",
        "try:\n",
        "    import numpy\n",
        "    print(\"numpy version:\", numpy.__version__)\n",
        "except ImportError:\n",
        "    print(\"numpy is not installed\")\n",
        "\n",
        "try:\n",
        "    import cv2\n",
        "    print(\"opencv-python version:\", cv2.__version__)  # OpenCV is often imported as cv2\n",
        "except ImportError:\n",
        "    print(\"opencv-python is not installed\")\n",
        "\n",
        "try:\n",
        "    import pandas\n",
        "    print(\"pandas version:\", pandas.__version__)\n",
        "except ImportError:\n",
        "    print(\"pandas is not installed\")\n",
        "\n",
        "try:\n",
        "    import PIL\n",
        "    print(\"Pillow version:\", PIL.__version__)\n",
        "except ImportError:\n",
        "    print(\"Pillow is not installed\")\n",
        "\n",
        "try:\n",
        "    import yaml\n",
        "    print(\"PyYAML version:\", yaml.__version__)\n",
        "except ImportError:\n",
        "    print(\"PyYAML is not installed\")\n",
        "\n",
        "try:\n",
        "    import scipy\n",
        "    print(\"scipy version:\", scipy.__version__)\n",
        "except ImportError:\n",
        "    print(\"scipy is not installed\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "except ImportError:\n",
        "    print(\"PyTorch is not installed\")\n",
        "\n",
        "try:\n",
        "    import torchvision\n",
        "    print(\"torchvision version:\", torchvision.__version__)\n",
        "except ImportError:\n",
        "    print(\"torchvision is not installed\")\n"
      ],
      "metadata": {
        "id": "QUqYWzmGMqIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Download Pretrained Models\n",
        "\n",
        "In this step, we'll download the pretrained models and place them under the `model_zoos` directory. Bash commands will be used to move the files into the appropriate folder.\n",
        "\n",
        "Please execute the following commands to download and organize the pretrained models.\n",
        "\n",
        "[link to the pre-trained models](https://huggingface.co/erickyue/rog_modelzoo/tree/main)\n"
      ],
      "metadata": {
        "id": "-bp0JLx1tJTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Uncomment the following lines if you're running it for the first time.\n",
        "\n",
        "#Change directory to the model_zoos folder\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/manogna-dp-project/rog/model_zoos\")\n",
        "\n",
        "#Print the current directory\n",
        "!pwd\n",
        "\n",
        "#Install git-lfs for handling large files\n",
        "!apt install git-lfs\n",
        "!git lfs install\n",
        "\n",
        "#Clone the repository containing pretrained models\n",
        "!git clone https://huggingface.co/erickyue/rog_modelzoo\n",
        "\n",
        "#Move the downloaded files to the current directory\n",
        "!mv -v /content/drive/MyDrive/manogna-dp-project/rog/model_zoos/rog_modelzoo/*  ./\n",
        "\n",
        "#Remove the empty rog_modelzoo directory\n",
        "!rm -rf rog_modelzoo/"
      ],
      "metadata": {
        "id": "H2K8wZyAElpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Access\n",
        "\n",
        "In order to reproduce the results, you need to access the shared dataset. I have shared the folder with Dr. Fan (Course Instructor) and Harshitha (Teaching Assistant). If you're using with different account, Please send me a request.\n",
        "\n",
        "1. Locate the shared folder link provided to you.\n",
        "2. Go to your Google Drive and click on \"Shared with me\" to find the folder.\n",
        "3. Right-click on the shared folder and select \"Add shortcut to Drive.\"\n",
        "4. Save the shortcut in the following directory: `/content/drive/MyDrive`.\n",
        "\n",
        "Once you have added the shortcut, you will be able to access the dataset from within the notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "AUpwp5LbAYHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NOTE: Here, you add shortcut to the shared folder and save it in /content/drive/MyDrive."
      ],
      "metadata": {
        "id": "eTEziKnpouQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code snippet changes the active directory. It is needed to avoid path conflicts later on."
      ],
      "metadata": {
        "id": "VmuTapAeufph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory where your data is located\n",
        "data_directory = \"/content/drive/MyDrive/manogna-dp-project/rog\"\n",
        "\n",
        "# Change the current directory to the data directory\n",
        "os.chdir(data_directory)\n",
        "\n",
        "# Print the current working directory after changing\n",
        "!pwd"
      ],
      "metadata": {
        "id": "4Ar45suOJWmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print Updated Datapair File\n",
        "\n",
        "I have updated the `datapair.dat` file to match the paths of the current dataset. Please note that the paths in the `datapair.dat` file have been modified to correspond to the paths in the current dataset, ensuring compatibility with the code execution.\n"
      ],
      "metadata": {
        "id": "Tma0a8LGuWSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code snippet to print some of the contents of datapair.dat\n",
        "\n",
        "# Define the path to the datapair file\n",
        "datapair_file_path = \"data/datapair.dat\"\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Load the datapair from the file\n",
        "with open(datapair_file_path, \"rb\") as fp:\n",
        "    record = pickle.load(fp)\n",
        "\n",
        "# Print the datapair\n",
        "print(\"datapair:\")\n",
        "for index, item in enumerate(record[\"data_pair\"]):\n",
        "    print(f\"Index {index}: {item}\")\n",
        "    if index == 10:\n",
        "      break\n",
        "\n",
        "# Check if 'root' key exists and print it if it does\n",
        "if \"root\" in record:\n",
        "    print(f\"Root directory: {record['root']}\")\n"
      ],
      "metadata": {
        "id": "nrMibKyqPMBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the Model and Evaluating the Performance\n",
        "\n",
        "The following snippets run some of the examples. The results will be stored under the `experiments` directory.\n",
        "\n",
        "Peak Signal-to-Noise Ratio (PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch Similarity (LPIPS) of the results are evaluated and printed.\n",
        "\n",
        "Original and reconstructed images (for minimum runnable image set) are also displayed in the experiments folder to visualize the results.\n"
      ],
      "metadata": {
        "id": "DHxhhWSququf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py"
      ],
      "metadata": {
        "id": "xkZBLfizFrS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 attack_fedavg.py"
      ],
      "metadata": {
        "id": "CRjA1VExYsua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}